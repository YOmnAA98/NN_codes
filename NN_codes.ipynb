{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19059008.0\n"
     ]
    }
   ],
   "source": [
    "N,D,H = 64,1000,100\n",
    "x = tf.placeholder(tf.float32, shape=(N, D))\n",
    "y = tf.placeholder(tf.float32, shape=(N, D))\n",
    "w1 = tf.placeholder(tf.float32, shape=(D, H))\n",
    "w2 = tf.placeholder(tf.float32, shape=(H, D))\n",
    "\n",
    "h = tf.maximum(tf.matmul(x, w1), 0)\n",
    "y_pred = tf.matmul(h, w2)\n",
    "diff = y_pred - y\n",
    "loss = tf.reduce_mean(tf.reduce_sum(diff ** 2 , axis=1))\n",
    "\n",
    "grad_w1,grad_w2=tf.gradients(loss,[w1,w2])\n",
    "\n",
    "with tf.Session() as sess :\n",
    "    values = {x: np.random.rand(N,D),\n",
    "              w1:np.random.randn(D,H),\n",
    "              w2:np.random.randn(H,D),\n",
    "              y: np.random.randn(N,D),\n",
    "             }\n",
    "    out=sess.run([loss,grad_w1,grad_w2 ],feed_dict=values)\n",
    "    loss_val,grad_w1_val,grad_w2_val = out\n",
    "    print(loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17438216.0\n",
      "258250.92\n",
      "47073.04\n",
      "30434.434\n",
      "21711.139\n",
      "16289.041\n",
      "12591.096\n",
      "9955.653\n",
      "8011.6143\n",
      "6537.202\n",
      "5401.6387\n",
      "4516.284\n",
      "3815.7532\n",
      "3258.7124\n",
      "2814.5137\n",
      "2459.462\n",
      "2175.1545\n",
      "1947.118\n",
      "1764.0399\n",
      "1616.9072\n",
      "1498.5383\n",
      "1403.2115\n",
      "1326.4233\n",
      "1264.5508\n",
      "1214.6792\n",
      "1174.4822\n",
      "1142.0554\n",
      "1115.883\n",
      "1094.7186\n",
      "1077.635\n",
      "1063.8408\n",
      "1052.6982\n",
      "1043.6997\n",
      "1036.4333\n",
      "1030.565\n",
      "1025.8239\n",
      "1021.9924\n",
      "1018.9015\n",
      "1016.4088\n",
      "1014.3938\n",
      "1012.765\n",
      "1011.4484\n",
      "1010.3857\n",
      "1009.5283\n",
      "1008.8393\n",
      "1008.28674\n",
      "1007.84784\n",
      "1007.49304\n",
      "1007.20605\n",
      "1006.9778\n"
     ]
    }
   ],
   "source": [
    "N,D,H = 64,1000,100\n",
    "x = tf.placeholder(tf.float32, shape=(N, D))\n",
    "y = tf.placeholder(tf.float32, shape=(N, D))\n",
    "w1 = tf.placeholder(tf.float32, shape=(D, H))\n",
    "w2 = tf.placeholder(tf.float32, shape=(H, D))\n",
    "\n",
    "h = tf.maximum(tf.matmul(x, w1), 0)\n",
    "y_pred = tf.matmul(h, w2)\n",
    "diff = y_pred - y\n",
    "loss = tf.reduce_mean(tf.reduce_sum(diff ** 2 , axis=1))\n",
    "\n",
    "grad_w1,grad_w2=tf.gradients(loss,[w1,w2])\n",
    "\n",
    "with tf.Session() as sess :\n",
    "    values = {x: np.random.rand(N,D),\n",
    "              w1:np.random.randn(D,H),\n",
    "              w2:np.random.randn(H,D),\n",
    "              y: np.random.randn(N,D),\n",
    "             }\n",
    "    \n",
    "    learning_rate = 1e-5\n",
    "    for t in range(50):\n",
    "        out = sess.run([loss,grad_w1,grad_w2],\n",
    "                      feed_dict=values)\n",
    "        loss_val,grad_w1_val,grad_w2_val = out\n",
    "        values[w1] -= learning_rate * grad_w1_val\n",
    "        values[w2] -= learning_rate * grad_w2_val\n",
    "        print(loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50479030.0\n",
      "50479030.0\n",
      "50479030.0\n",
      "50479030.0\n",
      "50479030.0\n",
      "50479030.0\n",
      "50479030.0\n",
      "50479030.0\n",
      "50479030.0\n",
      "50479030.0\n",
      "50479030.0\n",
      "50479030.0\n",
      "50479030.0\n",
      "50479030.0\n",
      "50479030.0\n",
      "50479030.0\n",
      "50479030.0\n",
      "50479030.0\n",
      "50479030.0\n",
      "50479030.0\n",
      "50479030.0\n",
      "50479030.0\n",
      "50479030.0\n",
      "50479030.0\n",
      "50479030.0\n",
      "50479030.0\n",
      "50479030.0\n",
      "50479030.0\n",
      "50479030.0\n",
      "50479030.0\n",
      "50479030.0\n",
      "50479030.0\n",
      "50479030.0\n",
      "50479030.0\n",
      "50479030.0\n",
      "50479030.0\n",
      "50479030.0\n",
      "50479030.0\n",
      "50479030.0\n",
      "50479030.0\n",
      "50479030.0\n",
      "50479030.0\n",
      "50479030.0\n",
      "50479030.0\n",
      "50479030.0\n",
      "50479030.0\n",
      "50479030.0\n",
      "50479030.0\n",
      "50479030.0\n",
      "50479030.0\n"
     ]
    }
   ],
   "source": [
    "N,D,H = 64,1000,100\n",
    "x = tf.placeholder(tf.float32, shape=(N, D))\n",
    "y = tf.placeholder(tf.float32, shape=(N, D))\n",
    "w1 = tf.Variable(tf.random_normal((D, H)))\n",
    "w2 = tf.Variable(tf.random_normal((H, D))) \n",
    "\n",
    "\n",
    "h = tf.maximum(tf.matmul(x, w1), 0)\n",
    "y_pred = tf.matmul(h, w2)\n",
    "diff = y_pred - y\n",
    "loss = tf.reduce_mean(tf.reduce_sum(diff ** 2 , axis=1))\n",
    "\n",
    "grad_w1,grad_w2=tf.gradients(loss,[w1,w2])\n",
    "\n",
    "learning_rate = 1e-5\n",
    "new_w1= w1.assign(w1 - learning_rate * grad_w1)\n",
    "new_w2= w2.assign(w2 - learning_rate * grad_w2)\n",
    "\n",
    "with tf.Session() as sess :\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    values = {x : np.random.randn(N,D),\n",
    "              y : np.random.randn(N,D), }\n",
    "    for t in range(50) :\n",
    "        loss_val, = sess.run([loss], feed_dict=values)\n",
    "        print(loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50511040.0\n",
      "17798460.0\n",
      "9348950.0\n",
      "5498241.0\n",
      "3457734.5\n",
      "2276076.0\n",
      "1548814.0\n",
      "1080606.9\n",
      "769167.44\n",
      "556202.0\n",
      "407479.75\n",
      "301631.44\n",
      "225314.89\n",
      "169547.11\n",
      "128503.09\n",
      "98009.73\n",
      "75170.42\n",
      "57940.56\n",
      "44885.977\n",
      "34942.297\n",
      "27329.963\n",
      "21472.967\n",
      "16963.098\n",
      "13476.274\n",
      "10770.66\n",
      "8666.428\n",
      "7025.3223\n",
      "5741.6934\n",
      "4736.134\n",
      "3946.6519\n",
      "3325.6323\n",
      "2836.3599\n",
      "2450.2144\n",
      "2145.0652\n",
      "1903.5813\n",
      "1712.2847\n",
      "1560.5004\n",
      "1440.0736\n",
      "1344.4143\n",
      "1268.4106\n",
      "1207.935\n",
      "1159.7982\n",
      "1121.4534\n",
      "1090.9077\n",
      "1066.597\n",
      "1047.2551\n",
      "1031.8445\n",
      "1019.5837\n",
      "1009.86676\n",
      "1002.16284\n"
     ]
    }
   ],
   "source": [
    "N,D,H = 64,1000,100\n",
    "x = tf.placeholder(tf.float32, shape=(N, D))\n",
    "y = tf.placeholder(tf.float32, shape=(N, D))\n",
    "w1 = tf.Variable(tf.random_normal((D, H)))\n",
    "w2 = tf.Variable(tf.random_normal((H, D)))\n",
    "\n",
    "\n",
    "h = tf.maximum(tf.matmul(x, w1), 0)\n",
    "y_pred = tf.matmul(h, w2)\n",
    "diff = y_pred - y\n",
    "loss = tf.reduce_mean(tf.reduce_sum(diff ** 2 , axis=1))\n",
    "\n",
    "grad_w1,grad_w2=tf.gradients(loss,[w1,w2])\n",
    "\n",
    "learning_rate = 1e-5\n",
    "new_w1= w1.assign(w1 - learning_rate * grad_w1)\n",
    "new_w2= w2.assign(w2 - learning_rate * grad_w2)\n",
    "\n",
    "updates = tf.group(new_w1, new_w2)\n",
    "\n",
    "with tf.Session() as sess :\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    values = {x : np.random.randn(N,D),\n",
    "              y : np.random.randn(N,D), }\n",
    "    \n",
    "    losses = []\n",
    "    for t in range(50):\n",
    "        loss_val, _ = sess.run([loss, updates] ,  feed_dict = values)\n",
    "        print(loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50433520.0\n",
      "17772142.0\n",
      "9291441.0\n",
      "5443239.0\n",
      "3414301.5\n",
      "2243990.5\n",
      "1527902.4\n",
      "1068446.2\n",
      "763127.0\n",
      "555000.9\n",
      "409125.2\n",
      "305385.28\n",
      "230504.84\n",
      "175711.22\n",
      "135160.47\n",
      "104767.266\n",
      "81798.19\n",
      "64275.938\n",
      "50807.703\n",
      "40382.14\n",
      "32253.438\n",
      "25888.836\n",
      "20886.21\n",
      "16936.412\n",
      "13800.407\n",
      "11304.995\n",
      "9312.862\n",
      "7714.4155\n",
      "6434.7607\n",
      "5406.3594\n",
      "4577.373\n",
      "3907.5125\n",
      "3365.1533\n",
      "2925.1753\n",
      "2567.6506\n",
      "2276.6497\n",
      "2039.5508\n",
      "1846.1328\n",
      "1688.1283\n",
      "1559.0117\n",
      "1453.3405\n",
      "1366.7986\n",
      "1295.9028\n",
      "1237.785\n",
      "1190.1294\n",
      "1151.0261\n",
      "1118.9325\n",
      "1092.6335\n",
      "1071.1003\n",
      "1053.4307\n"
     ]
    }
   ],
   "source": [
    "N,D,H = 64,1000,100\n",
    "x = tf.placeholder(tf.float32, shape=(N, D))\n",
    "y = tf.placeholder(tf.float32, shape=(N, D))\n",
    "w1 = tf.Variable(tf.random_normal((D, H)))\n",
    "w2 = tf.Variable(tf.random_normal((H, D)))\n",
    "\n",
    "\n",
    "h = tf.maximum(tf.matmul(x, w1), 0)\n",
    "y_pred = tf.matmul(h, w2)\n",
    "diff = y_pred - y\n",
    "loss = tf.reduce_mean(tf.reduce_sum(diff * diff , axis=1))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(1e-5)\n",
    "updates= optimizer.minimize(loss)\n",
    "\n",
    "with tf.Session() as sess :\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    values = {x : np.random.randn(N,D),\n",
    "              y : np.random.randn(N,D), }\n",
    "    \n",
    "    losses = []\n",
    "    for t in range(50):\n",
    "        loss_val, _ = sess.run([loss, updates] ,  feed_dict = values)\n",
    "        print(loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49143.69\n",
      "49098.31\n",
      "49053.133\n",
      "49008.008\n",
      "48962.996\n",
      "48917.85\n",
      "48872.863\n",
      "48828.082\n",
      "48783.17\n",
      "48738.418\n",
      "48693.74\n",
      "48649.06\n",
      "48604.594\n",
      "48559.94\n",
      "48515.465\n",
      "48471.156\n",
      "48426.73\n",
      "48382.438\n",
      "48338.33\n",
      "48294.12\n",
      "48250.05\n",
      "48205.883\n",
      "48162.02\n",
      "48118.09\n",
      "48074.27\n",
      "48030.46\n",
      "47986.684\n",
      "47943.06\n",
      "47899.44\n",
      "47855.9\n",
      "47812.406\n",
      "47768.97\n",
      "47725.617\n",
      "47682.25\n",
      "47638.945\n",
      "47595.844\n",
      "47552.65\n",
      "47509.586\n",
      "47466.617\n",
      "47423.633\n",
      "47380.723\n",
      "47337.76\n",
      "47294.996\n",
      "47252.31\n",
      "47209.73\n",
      "47167.11\n",
      "47124.543\n",
      "47082.016\n",
      "47039.582\n",
      "46997.203\n"
     ]
    }
   ],
   "source": [
    "N,D,H = 64,1000,100\n",
    "x = tf.placeholder(tf.float32, shape=(N, D))\n",
    "y = tf.placeholder(tf.float32, shape=(N, D))\n",
    "w1 = tf.Variable(tf.random_normal((D, H)))\n",
    "w2 = tf.Variable(tf.random_normal((H, D)))\n",
    "\n",
    "h = tf.maximum(tf.matmul(x, w1), 0)\n",
    "y_pred = tf.matmul(h, w2)\n",
    "\n",
    "loss = tf.losses.mean_squared_error(y_pred, y)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(1e-5)\n",
    "updates= optimizer.minimize(loss)\n",
    "\n",
    "\n",
    "with tf.Session() as sess :\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    values = {x : np.random.randn(N,D),\n",
    "              y : np.random.randn(N,D), }\n",
    "    \n",
    "  \n",
    "    for t in range(50):\n",
    "        loss_val, _ = sess.run([loss, updates] ,  feed_dict = values)\n",
    "        print(loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.947858\n",
      "2.9478297\n",
      "2.9478016\n",
      "2.9477746\n",
      "2.9477463\n",
      "2.9477174\n",
      "2.9476895\n",
      "2.9476614\n",
      "2.947632\n",
      "2.9476047\n",
      "2.9475763\n",
      "2.9475484\n",
      "2.9475203\n",
      "2.9474914\n",
      "2.9474626\n",
      "2.9474332\n",
      "2.9474044\n",
      "2.947376\n",
      "2.9473493\n",
      "2.9473224\n",
      "2.9472928\n",
      "2.9472659\n",
      "2.9472375\n",
      "2.9472091\n",
      "2.9471827\n",
      "2.947155\n",
      "2.9471266\n",
      "2.9470978\n",
      "2.947068\n",
      "2.9470422\n",
      "2.9470139\n",
      "2.9469852\n",
      "2.9469564\n",
      "2.9469275\n",
      "2.9468994\n",
      "2.9468727\n",
      "2.9468446\n",
      "2.9468193\n",
      "2.9467916\n",
      "2.9467652\n",
      "2.946737\n",
      "2.9467092\n",
      "2.9466803\n",
      "2.9466524\n",
      "2.9466217\n",
      "2.9465947\n",
      "2.9465666\n",
      "2.9465387\n",
      "2.946511\n",
      "2.9464827\n"
     ]
    }
   ],
   "source": [
    "N,D,H = 64,1000,100\n",
    "x = tf.placeholder(tf.float32, shape=(N, D))\n",
    "y = tf.placeholder(tf.float32, shape=(N, D))\n",
    "\n",
    "init = tf.variance_scaling_initializer(2.0)\n",
    "h = tf.layers.dense(inputs=x , units=H,activation = tf.nn.relu, kernel_initializer=init)\n",
    "y_pred = tf.layers.dense(inputs=h, units = D, kernel_initializer=init)\n",
    "\n",
    "loss = tf.losses.mean_squared_error(y_pred, y)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(1e-5)\n",
    "updates= optimizer.minimize(loss)\n",
    "\n",
    "\n",
    "with tf.Session() as sess :\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    values = {x : np.random.randn(N,D),\n",
    "              y : np.random.randn(N,D), }\n",
    "    \n",
    "  \n",
    "    for t in range(50):\n",
    "        loss_val, _ = sess.run([loss, updates] ,  feed_dict = values)\n",
    "        print(loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1604295\n",
      "1.1239173\n",
      "1.0952939\n",
      "1.0722972\n",
      "1.0534751\n",
      "1.0378313\n",
      "1.0246654\n",
      "1.0134362\n",
      "1.0037433\n",
      "0.995337\n",
      "0.9879815\n",
      "0.9814977\n",
      "0.9757397\n",
      "0.97060454\n",
      "0.96598834\n",
      "0.96180564\n",
      "0.9579583\n",
      "0.95440716\n",
      "0.95110923\n",
      "0.94802415\n",
      "0.94510293\n",
      "0.94232094\n",
      "0.9396682\n",
      "0.93711966\n",
      "0.9346368\n",
      "0.93222004\n",
      "0.9298499\n",
      "0.9275148\n",
      "0.9252123\n",
      "0.92292756\n",
      "0.9206497\n",
      "0.9183765\n",
      "0.9160953\n",
      "0.91380644\n",
      "0.91151273\n",
      "0.90920615\n",
      "0.9068843\n",
      "0.9045446\n",
      "0.9021831\n",
      "0.8998019\n",
      "0.89739054\n",
      "0.8949511\n",
      "0.8924833\n",
      "0.8899837\n",
      "0.887452\n",
      "0.88487667\n",
      "0.8822704\n",
      "0.8796297\n",
      "0.87694955\n",
      "0.8742358\n"
     ]
    }
   ],
   "source": [
    "N,D,H = 64,1000,100\n",
    "x = tf.placeholder(tf.float32, shape=(N, D))\n",
    "y = tf.placeholder(tf.float32, shape=(N, D))\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(H, input_shape=(D,),activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(D))\n",
    "y_pred = model(x)\n",
    "loss= tf.losses.mean_squared_error(y_pred, y)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(1e0)\n",
    "updates= optimizer.minimize(loss)\n",
    "\n",
    "\n",
    "with tf.Session() as sess :\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    values = {x : np.random.randn(N,D),\n",
    "              y : np.random.randn(N,D), }\n",
    "    \n",
    "  \n",
    "    for t in range(50):\n",
    "        loss_val, _ = sess.run([loss, updates] ,  feed_dict = values)\n",
    "        print(loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 1.1544\n",
      "Epoch 2/50\n",
      "64/64 [==============================] - 0s 157us/step - loss: 1.1189\n",
      "Epoch 3/50\n",
      "64/64 [==============================] - 0s 110us/step - loss: 1.0910\n",
      "Epoch 4/50\n",
      "64/64 [==============================] - 0s 133us/step - loss: 1.0686\n",
      "Epoch 5/50\n",
      "64/64 [==============================] - 0s 110us/step - loss: 1.0503\n",
      "Epoch 6/50\n",
      "64/64 [==============================] - 0s 149us/step - loss: 1.0350\n",
      "Epoch 7/50\n",
      "64/64 [==============================] - 0s 110us/step - loss: 1.0222\n",
      "Epoch 8/50\n",
      "64/64 [==============================] - 0s 141us/step - loss: 1.0114\n",
      "Epoch 9/50\n",
      "64/64 [==============================] - 0s 141us/step - loss: 1.0021\n",
      "Epoch 10/50\n",
      "64/64 [==============================] - 0s 125us/step - loss: 0.9940\n",
      "Epoch 11/50\n",
      "64/64 [==============================] - 0s 164us/step - loss: 0.9869\n",
      "Epoch 12/50\n",
      "64/64 [==============================] - 0s 102us/step - loss: 0.9807\n",
      "Epoch 13/50\n",
      "64/64 [==============================] - 0s 172us/step - loss: 0.9753\n",
      "Epoch 14/50\n",
      "64/64 [==============================] - 0s 102us/step - loss: 0.9704\n",
      "Epoch 15/50\n",
      "64/64 [==============================] - 0s 149us/step - loss: 0.9660\n",
      "Epoch 16/50\n",
      "64/64 [==============================] - 0s 125us/step - loss: 0.9620\n",
      "Epoch 17/50\n",
      "64/64 [==============================] - 0s 117us/step - loss: 0.9583\n",
      "Epoch 18/50\n",
      "64/64 [==============================] - 0s 133us/step - loss: 0.9549\n",
      "Epoch 19/50\n",
      "64/64 [==============================] - 0s 125us/step - loss: 0.9517\n",
      "Epoch 20/50\n",
      "64/64 [==============================] - 0s 141us/step - loss: 0.9487\n",
      "Epoch 21/50\n",
      "64/64 [==============================] - 0s 110us/step - loss: 0.9459\n",
      "Epoch 22/50\n",
      "64/64 [==============================] - 0s 157us/step - loss: 0.9432\n",
      "Epoch 23/50\n",
      "64/64 [==============================] - 0s 110us/step - loss: 0.9406\n",
      "Epoch 24/50\n",
      "64/64 [==============================] - 0s 180us/step - loss: 0.9381\n",
      "Epoch 25/50\n",
      "64/64 [==============================] - 0s 78us/step - loss: 0.9357\n",
      "Epoch 26/50\n",
      "64/64 [==============================] - 0s 157us/step - loss: 0.9333\n",
      "Epoch 27/50\n",
      "64/64 [==============================] - 0s 141us/step - loss: 0.9310\n",
      "Epoch 28/50\n",
      "64/64 [==============================] - 0s 117us/step - loss: 0.9287\n",
      "Epoch 29/50\n",
      "64/64 [==============================] - 0s 180us/step - loss: 0.9264\n",
      "Epoch 30/50\n",
      "64/64 [==============================] - 0s 117us/step - loss: 0.9242\n",
      "Epoch 31/50\n",
      "64/64 [==============================] - 0s 164us/step - loss: 0.9219\n",
      "Epoch 32/50\n",
      "64/64 [==============================] - 0s 172us/step - loss: 0.9196\n",
      "Epoch 33/50\n",
      "64/64 [==============================] - 0s 110us/step - loss: 0.9174\n",
      "Epoch 34/50\n",
      "64/64 [==============================] - 0s 165us/step - loss: 0.9151\n",
      "Epoch 35/50\n",
      "64/64 [==============================] - 0s 164us/step - loss: 0.9128\n",
      "Epoch 36/50\n",
      "64/64 [==============================] - 0s 133us/step - loss: 0.9105\n",
      "Epoch 37/50\n",
      "64/64 [==============================] - 0s 141us/step - loss: 0.9082\n",
      "Epoch 38/50\n",
      "64/64 [==============================] - 0s 141us/step - loss: 0.9059\n",
      "Epoch 39/50\n",
      "64/64 [==============================] - 0s 165us/step - loss: 0.9035\n",
      "Epoch 40/50\n",
      "64/64 [==============================] - 0s 141us/step - loss: 0.9011\n",
      "Epoch 41/50\n",
      "64/64 [==============================] - 0s 149us/step - loss: 0.8987\n",
      "Epoch 42/50\n",
      "64/64 [==============================] - 0s 180us/step - loss: 0.8962\n",
      "Epoch 43/50\n",
      "64/64 [==============================] - 0s 102us/step - loss: 0.8937\n",
      "Epoch 44/50\n",
      "64/64 [==============================] - 0s 149us/step - loss: 0.8912\n",
      "Epoch 45/50\n",
      "64/64 [==============================] - 0s 86us/step - loss: 0.8887\n",
      "Epoch 46/50\n",
      "64/64 [==============================] - 0s 165us/step - loss: 0.8861\n",
      "Epoch 47/50\n",
      "64/64 [==============================] - 0s 188us/step - loss: 0.8835\n",
      "Epoch 48/50\n",
      "64/64 [==============================] - 0s 86us/step - loss: 0.8808\n",
      "Epoch 49/50\n",
      "64/64 [==============================] - 0s 188us/step - loss: 0.8781\n",
      "Epoch 50/50\n",
      "64/64 [==============================] - 0s 157us/step - loss: 0.8753\n"
     ]
    }
   ],
   "source": [
    "N,D,H = 64,1000,100\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(H, input_shape=(D,), activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(D))\n",
    "model.compile(loss=tf.keras.losses.mean_squared_error, optimizer=tf.keras.optimizers.SGD(lr=1e0))\n",
    "\n",
    "x= np.random.randn(N,D)\n",
    "y= np.random.randn(N,D)\n",
    "\n",
    "history = model.fit(x,y, epochs=50 , batch_size = N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NNlab",
   "language": "python",
   "name": "nnlab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
